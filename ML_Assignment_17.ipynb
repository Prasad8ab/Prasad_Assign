{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f87721c",
   "metadata": {},
   "source": [
    "1. Using a graph to illustrate slope and intercept, define basic linear regression.\n",
    "\n",
    "Basic linear regression is a statistical method that uses a straight line to model the relationship between two variables. The line is called the regression line, and it is drawn so that it minimizes the distance between itself and the data points. The slope of the regression line tells us how much the dependent variable changes as the independent variable changes. The intercept of the regression line tells us the value of the dependent variable when the independent variable is zero.\n",
    "\n",
    "2. In a graph, explain the terms rise, run, and slope.\n",
    "\n",
    "Rise is the change in the dependent variable (y) from one data point to the next. Run is the change in the independent variable (x) from one data point to the next. The slope of the line is equal to rise/run.\n",
    "\n",
    "3. Use a graph to demonstrate slope, linear positive slope, and linear negative slope, as well as the different conditions that contribute to the slope.\n",
    "\n",
    "Linear positive slope means that the dependent variable increases as the independent variable increases. Linear negative slope means that the dependent variable decreases as the independent variable increases. The steeper the slope, the stronger the relationship between the two variables.\n",
    "\n",
    "\n",
    "4. Use a graph to demonstrate curve linear negative slope and curve linear positive slope.\n",
    "\n",
    "Curve linear negative slope means that the dependent variable decreases as the independent variable increases, but the rate of decrease is not constant. Curve linear positive slope means that the dependent variable increases as the independent variable increases, but the rate of increase is not constant.\n",
    "\n",
    "\n",
    "5. Use a graph to show the maximum and low points of curves.\n",
    "\n",
    "The maximum and minimum points of curves are the points where the slope of the curve is zero.\n",
    "\n",
    "\n",
    "6. Use the formulas for a and b to explain ordinary least squares.\n",
    "\n",
    "Ordinary least squares (OLS) is a method for fitting a linear regression line to a set of data points. The OLS algorithm minimizes the sum of the squared residuals, which are the distances between the data points and the regression line.\n",
    "The formulas for a and b are as follows:\n",
    "\n",
    "a is the y-intercept, and it is equal to the average of the y-values minus the slope * average of the x-values.\n",
    "b is the slope, and it is equal to the sum of the products of the x-values and the y-values minus the sum of the x-values times the sum of the y-values divided by the sum of the squared x-values.\n",
    "\n",
    "7. Provide a step-by-step explanation of the OLS algorithm.\n",
    "The OLS algorithm works as follows:\n",
    "\n",
    "Start with a guess for the values of a and b.\n",
    "\n",
    "Calculate the sum of the squared residuals for the current values of a and b.\n",
    "\n",
    "Use a mathematical optimization algorithm to find new values of a and b that minimize the sum of the squared residuals.\n",
    "\n",
    "Repeat steps 2 and 3 until the sum of the squared residuals does not change significantly.\n",
    "\n",
    "\n",
    "8. What is the regression's standard error? To represent the same, make a graph.\n",
    "\n",
    "The standard error of the regression is a measure of the accuracy of the regression line. It is calculated as the square root of the mean squared error, which is the sum of the squared residuals divided by the number of data points.\n",
    "\n",
    "9. Provide an example of multiple linear regression.\n",
    "\n",
    "Multiple linear regression is a statistical method that uses multiple linear regression lines to model the relationship between a dependent variable and multiple independent variables. The lines are drawn so that they minimize the distance between themselves and the data points.\n",
    "\n",
    "\n",
    "10. Describe the regression analysis assumptions and the BLUE principle.\n",
    "\n",
    "The regression analysis assumptions are as follows:\n",
    "The independent variables are not correlated with each other.\n",
    "The dependent variable is normally distributed.\n",
    "The errors are normally distributed and have a constant variance.\n",
    "The errors are independent of each other.\n",
    "\n",
    "11. Describe two major issues with regression analysis.\n",
    "\n",
    "Two major issues with regression analysis are:\n",
    "Multicollinearity occurs when two or more independent variables are highly correlated with each other. This can cause problems with the accuracy of the regression model.\n",
    "Outliers are data points that are far away from the rest of the data points. Outliers can also cause problems with the accuracy of the regression model\n",
    "\n",
    "12. How can the linear regression model's accuracy be improved?\n",
    "\n",
    "Use more data. The more data you have, the more accurate your model will be. However, it is important to make sure that the data is of good quality and that it is representative of the population that you are trying to model.\n",
    "Use a more complex model. If the relationship between the independent and dependent variables is not linear, then you may need to use a more complex model, such as a polynomial regression model or a logistic regression model.\n",
    "Use regularization. Regularization is a technique that can help to improve the accuracy of a model by reducing the impact of outliers and noisy data. There are different types of regularization, such as ridge regression and LASSO regression.\n",
    "Use cross-validation. Cross-validation is a technique that can be used to evaluate the accuracy of a model on unseen data. This can help you to ensure that your model is not overfitting the training data.\n",
    "Use a different algorithm. There are different algorithms that can be used to fit a linear regression model. Some algorithms may be more accurate than others for a particular dataset.\n",
    "\n",
    "\n",
    "13. Using an example, describe the polynomial regression model in detail.\n",
    "\n",
    "Polynomial regression is a type of regression analysis that uses polynomial equations to model the relationship between two variables. Polynomial equations are equations that have terms of the independent variable raised to different powers. For example, a quadratic polynomial equation would have terms of the independent variable raised to the first and second power.\n",
    "Polynomial regression can be used to model relationships that are not linear. For example, if the relationship between two variables is quadratic, then a polynomial regression model with a quadratic term will be able to fit the data better than a linear regression model.\n",
    "\n",
    "14. Provide a detailed explanation of logistic regression.\n",
    "\n",
    "Logistic regression is a type of regression analysis that is used to model the probability of a binary outcome. A binary outcome is an outcome that can have only two values, such as \"yes\" or \"no\", \"true\" or \"false\", or \"success\" or \"failure\".\n",
    "Logistic regression models use a logistic function to model the probability of the binary outcome. The logistic function is a S-shaped curve that ranges from 0 to 1. The value of the logistic function at a given point on the curve represents the probability of the binary outcome occurring at that point.\n",
    "\n",
    "Logistic regression can be used to model a variety of phenomena, such as whether or not a customer will purchase a product, whether or not a patient will recover from an illness, or whether or not a student will pass an exam.\n",
    "\n",
    "15. What are the logistic regression assumptions?\n",
    "\n",
    "The logistic regression assumptions are as follows:\n",
    "The independent variables are not correlated with each other.\n",
    "The dependent variable is binary.\n",
    "The errors are normally distributed and have a constant variance.\n",
    "The errors are independent of each other.\n",
    "\n",
    "16. Go through the details of maximum likelihood estimation.\n",
    "\n",
    "Maximum likelihood estimation is a method for estimating the parameters of a statistical model. The maximum likelihood estimator is the value of the parameters that maximizes the likelihood of the observed data.\n",
    "In logistic regression, the maximum likelihood estimator is found by solving the following equation:\n",
    "\n",
    "L = P(y_1 | x_1, \\theta) * P(y_2 | x_2, \\theta) * ... * P(y_n | x_n, \\theta)\n",
    "\n",
    "where:\n",
    "\n",
    "L is the likelihood of the observed data\n",
    "y i  is the binary outcome for the $i$th data point\n",
    "x i   is the vector of independent variables for the $i$th data point\n",
    "Î¸ is the vector of parameters of the logistic regression model\n",
    "\n",
    "The maximum likelihood estimator can be found using a variety of numerical optimization algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
